import streamlit as st
from PIL import Image
import torch
import json
from torchvision import transforms
from models.cnn_model import CNNModel
# from grad_cam import GradCAM, overlay_heatmap_on_image
import matplotlib.pyplot as plt
import cv2
import numpy as np
from torchvision.transforms import ToPILImage
from utils import preprocess_image, load_model,inference

st.set_page_config(page_title="í—¤ì–´ìŠ¤íƒ€ì¼ ë¶„ë¥˜ê¸°", layout="centered")

st.title("âœ¨ HairNet âœ¨")

for key in ["gender", "style_type"]:
    if key not in st.session_state:
        st.session_state[key]=None

with open("style_descriptions.json", "r", encoding="utf-8") as f:
    STYLE_DESCRIPTION=json.load(f)

# ì²«í™”ë©´, ì„±ë³„ ì„ íƒ
if st.session_state.gender is None:
    st.markdown("### ğŸ‘‰ ì„±ë³„ì„ ì„ íƒí•´ì£¼ì„¸ìš”")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ‘¨ ë‚¨ì"):
            st.session_state.gender = "male"
            st.rerun()
    with col2:
        if st.button("ğŸ‘© ì—¬ì"):
            st.session_state.gender = "female"
            st.rerun()

# ë‘ë²ˆì§¸, ìŠ¤íƒ€ì¼ ì„ íƒ(íŒ/ì»·)
elif st.session_state.style_type is None:
    st.markdown(f"### ğŸ‘‰ { 'ë‚¨ì„±' if st.session_state.gender == 'male' else 'ì—¬ì„±' } í—¤ì–´ìŠ¤íƒ€ì¼ ìœ í˜•ì„ ì„ íƒí•´ì£¼ì„¸ìš”")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("âœ‚ï¸ ì»· ìŠ¤íƒ€ì¼"):
            st.session_state.style_type = "cut"
            st.rerun()
    with col2:
        if st.button("ğŸ’ˆ íŒ ìŠ¤íƒ€ì¼"):
            st.session_state.style_type = "perm"
            st.rerun()            

# ì„¸ë²ˆì§¸, ì´ë¯¸ì§€ ì—…ë¡œë“œ í˜ì´ì§€
else:
    gender = st.session_state.gender
    style_type = st.session_state.style_type
    combo_key = f"{gender}_{style_type}"

    CLASS_MAP= {
        "male_cut":["í¬ë¡­ì»·", "ëŒ„ë””ì»·", "í•„ëŸ¬ìŠ¤ì»·","ê°€ì¼ì»·", "í¬ë§ˆë“œì»·", "ë¦¬ì  íŠ¸ì»·"],
        "male_perm":["ì• ì¦ˆíŒ", "íˆí”¼íŒ", "ë¦¬í”„íŒ", "ì‰ë„ìš°íŒ", "ìŠ¤ì™ˆë¡œíŒ"],
        "female_cut":["íˆë©”ì»·", "í—ˆì‰¬ì»·", "ë ˆì´ì–´ë“œì»·", "ëª¨ì¦ˆì»·", "ìŠ¬ë¦­ì»·", "í…ŒìŠ¬ì»·"],
        "female_perm":["ë¹Œë“œíŒ", "êµ¬ë¦„íŒ", "ê·¸ë ˆì´ìŠ¤íŒ", "íˆí”¼íŒ"]
    }
    MODEL_PATHS={
        "male_cut":"best_model/male_cut.pth",
        "male_perm":"best_model/male_perm.pth",
        "female_cut":"best_model/female_cut.pth",
        "female_perm":"best_model/female_perm.pth"
    }
    style_kor = {
        "male": "ğŸ‘¨ ë‚¨ì„±",
        "female": "ğŸ‘© ì—¬ì„±",
        "cut": "ì»· ìŠ¤íƒ€ì¼",
        "perm": "íŒ ìŠ¤íƒ€ì¼"
    }

    gender_kor = style_kor.get(gender, "")
    style_type_kor = style_kor.get(style_type, "")

    # ì•ˆë‚´ ë¬¸êµ¬ ì¶œë ¥
    st.markdown(f"### {gender_kor} {style_type_kor} ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")

    CLASSES=CLASS_MAP[combo_key]
    model_path=MODEL_PATHS[combo_key]
    num_classes =len(CLASSES)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # model = load_model(model_path, device, num_classes)
    # target_layer=model.features[-2]
    
    #íŒŒì¼ ì—…ë¡œë“œ 
    uploaded_file = st.file_uploader("", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
        #ì´ë¯¸ì§€ -> Tensorë¡œ ë³€í™˜    
        input_tensor = preprocess_image(image)
        
        #ì—ëŸ¬ë©”ì‹œì§€
        if input_tensor is None:
            st.error("â— ì–¼êµ´ì´ í•˜ë‚˜ë§Œ ë‚˜ì˜¨ ì‚¬ì§„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:   
            input_tensor.to(device)
            #ëª¨ë¸ì— ì¸í’‹í…ì„œë¥¼ ì…ë ¥
            pred_class, result = inference(input_tensor, model_path, num_classes, CLASSES)

            st.markdown(f"### í—¤ì–´ìŠ¤íƒ€ì¼ ğŸ’‡ **{pred_class}** ({result}%)")
            
            #ì˜ˆì¸¡ê²°ê³¼ í•´ë‹¹í•˜ëŠ” ìŠ¤íƒ€ì¼ ì„¤ëª… ë¶ˆëŸ¬ì˜´
            if pred_class in STYLE_DESCRIPTION:
                description = STYLE_DESCRIPTION[pred_class].replace("\n", "<br>")
                st.markdown(f"""
                <div style='
                    font-family: "Apple SD Gothic Neo", "Malgun Gothic", sans-serif;
                    font-size: 16px;
                    line-height: 1.6;
                    padding: 10px;
                    background-color: #f9f9f9;
                    border-radius: 10px;
                    border: 1px solid #ddd;
                '>
                <strong>ğŸ’¬ ìŠ¤íƒ€ì¼ ì„¤ëª…</strong><br>{description}
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown("&nbsp;", unsafe_allow_html=True)
            if st.button("ì²˜ìŒìœ¼ë¡œ"):
                st.session_state.gender =None
                st.session_state.style_type =None
                st.rerun()
            #plot_probabilities(result, CLASSES)
            
            # topil=ToPILImage()
            # st.image(topil(input_tensor.squeeze(0)))
            # gradcam=GradCAM(model, target_layer)
            # heatmap=gradcam.generate(input_tensor)
            # overlay = overlay_heatmap_on_image(heatmap,image)
            # st.image(overlay, caption="Grad-cam", use_container_width=True)
            # ({probs.max().item()*100:.2f}%)      
